# LLMen
An custom instruction tuned version of Llama3.2-3B!
### Team TheLLMen entry for the CSE476 (Intro to Natural Language Processing) LLM competition
Result: We didn't place, but we sure learned a good deal about LLMs and how they work!

## Overview:
  - Base Model: meta-llama/Llama-3.2-3B, fine tuned with 4-bit QLora
  - Inference optimizations:
    - Few Shot CoT prompting
    - Attempt at RAG (Retrieval Augmented Generation) via langchain
  
## Results
  todo, we never had a formalized testing framework
  
   
## Ideas if we had more time: 
 - testing framework
 - safety alignment (DPO, GRPO)
 - Self-consistency (majority vote)
 - prompt selection
 - Better RAG implementation
