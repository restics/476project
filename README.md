# LLMen
An custom instruction tuned version of Llama3.2-3B!
### Team TheLLMen entry for the CSE476 (Intro to Natural Language Processing) LLM competition
Result: We didn't place, but we sure learned a good deal about LLMs and how they work!

## Overview:
  Base Model: meta-llama/Llama-3.2-3B, fine tuned with 4-bit QLora
  Inference optimizations:
    - Few Shot CoT prompting
    - Attempt at RAG (Retrieval Augmented Generation) via langchain
  
## Results
  todo ig
  
   
Ideas if we had more time:
 - safety alignment (DPO, GRPO)
 - Self-consistency (majority vote)
 - prompt selection
 - Better RAG implementation
